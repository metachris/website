<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Machine Learning on Chris Hager</title><link>https://www.metachris.dev/tags/machine-learning/</link><description>Recent content in Machine Learning on Chris Hager</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Sun, 22 Nov 2015 00:00:00 +0000</lastBuildDate><atom:link href="https://www.metachris.dev/tags/machine-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>Machine Learning on Amazon AWS GPU Instances</title><link>https://www.metachris.dev/2015/11/machine-learning-on-amazon-aws-gpu-instances/</link><pubDate>Sun, 22 Nov 2015 00:00:00 +0000</pubDate><guid>https://www.metachris.dev/2015/11/machine-learning-on-amazon-aws-gpu-instances/</guid><description>Machine learning algorithms regularly utilize GPUs to parallelize computations, and Amazon AWS GPU Instances provide cheap and on-demand access to capable virtual servers with NVIDIA GPUs.
GPU Instances come in two flavors: G2.2xlarge and G2.8xlarge:
Model GPUs vCPU Mem (GiB) SSD Storage (GB) g2.2xlarge 1 8 15 1 x 60 g2.8xlarge 4 32 60 2 x 120 The GPU instances feature Intel Xeon E5-2670 (Sandy Bridge) Processors and NVIDIA GPUs with 1,536 CUDA cores and 4GB of video memory each.</description></item></channel></rss>