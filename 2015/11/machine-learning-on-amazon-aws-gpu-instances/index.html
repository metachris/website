<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="Chris Hager"><meta name=description content="Machine learning algorithms regularly utilize GPUs to parallelize computations, and Amazon AWS GPU Instances provide cheap and on-demand access to capable virtual servers with NVIDIA GPUs.
GPU Instances come in two flavors: G2.2xlarge and G2.8xlarge:
Model GPUs vCPU Mem (GiB) SSD Storage (GB) g2.2xlarge 1 8 15 1 x 60 g2.8xlarge 4 32 60 2 x 120 The GPU instances feature Intel Xeon E5-2670 (Sandy Bridge) Processors and NVIDIA GPUs with 1,536 CUDA cores and 4GB of video memory each."><meta name=keywords content><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://www.metachris.dev/images/profile2-round.png"><meta name=twitter:title content="Machine Learning on Amazon AWS GPU Instances"><meta name=twitter:description content="Machine learning algorithms regularly utilize GPUs to parallelize computations, and Amazon AWS GPU Instances provide cheap and on-demand access to capable virtual servers with NVIDIA GPUs.
GPU Instances come in two flavors: G2.2xlarge and G2.8xlarge:
Model GPUs vCPU Mem (GiB) SSD Storage (GB) g2.2xlarge 1 8 15 1 x 60 g2.8xlarge 4 32 60 2 x 120 The GPU instances feature Intel Xeon E5-2670 (Sandy Bridge) Processors and NVIDIA GPUs with 1,536 CUDA cores and 4GB of video memory each."><meta property="og:title" content="Machine Learning on Amazon AWS GPU Instances"><meta property="og:description" content="Machine learning algorithms regularly utilize GPUs to parallelize computations, and Amazon AWS GPU Instances provide cheap and on-demand access to capable virtual servers with NVIDIA GPUs.
GPU Instances come in two flavors: G2.2xlarge and G2.8xlarge:
Model GPUs vCPU Mem (GiB) SSD Storage (GB) g2.2xlarge 1 8 15 1 x 60 g2.8xlarge 4 32 60 2 x 120 The GPU instances feature Intel Xeon E5-2670 (Sandy Bridge) Processors and NVIDIA GPUs with 1,536 CUDA cores and 4GB of video memory each."><meta property="og:type" content="article"><meta property="og:url" content="https://www.metachris.dev/2015/11/machine-learning-on-amazon-aws-gpu-instances/"><meta property="og:image" content="https://www.metachris.dev/images/profile2-round.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2015-11-22T00:00:00+00:00"><meta property="article:modified_time" content="2015-11-22T00:00:00+00:00"><base href=https://www.metachris.dev/2015/11/machine-learning-on-amazon-aws-gpu-instances/><title>Machine Learning on Amazon AWS GPU Instances Â· Chris Hager
</title><link rel=canonical href=https://www.metachris.dev/2015/11/machine-learning-on-amazon-aws-gpu-instances/><link rel=stylesheet href=https://www.metachris.dev/css/normalize.min.css><link rel=stylesheet href=https://www.metachris.dev/css/coder.min.5c8e001348b649d568cfadc57f153d76205f755a7d8b571532a28da454f20d18.css integrity="sha256-XI4AE0i2SdVoz63FfxU9diBfdVp9i1cVMqKNpFTyDRg=" crossorigin=anonymous media=screen><link rel=stylesheet href=https://www.metachris.dev/css/coder-dark.min.47e2bf508bd8d2609f50751fec4e8bea1d7d66645d0a2fb25c4a43f5ecac097b.css integrity="sha256-R+K/UIvY0mCfUHUf7E6L6h19ZmRdCi+yXEpD9eysCXs=" crossorigin=anonymous media=screen><script src=https://www.metachris.dev/js/custom.js></script><link rel=stylesheet href=https://www.metachris.dev/scss/custom.min.6250cbac2cbeff963e4f8fe342566948e00c953ece0ccbfe8c71d1c7cf3cf84b.css integrity="sha256-YlDLrCy+/5Y+T4/jQlZpSOAMlT7ODMv+jHHRx888+Es=" crossorigin=anonymous media=screen><link rel=icon type=image/png href=https://www.metachris.dev/images/favicon-32px.png sizes=32x32><link rel=icon type=image/png href=https://www.metachris.dev/images/favicon-16px.png sizes=16x16><link rel=alternate type=application/rss+xml href=https://www.metachris.devindex.xml title="Site Title"></head><body class=colorscheme-auto><main class=wrapper><nav class=navigation><section class=container><a class=navigation-title href=https://www.metachris.dev/>Chris Hager
</a><input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><svg width="20" height="20" viewBox="0 0 20 20" fill="currentcolor" aria-hidden="true"><path fill-rule="evenodd" d="M3 5a1 1 0 011-1h12a1 1 0 110 2H4A1 1 0 013 5zm0 5a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zm0 5a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1z" clip-rule="evenodd"/></svg></label><ul class=navigation-list><li class=navigation-item><a class=navigation-link href=https://www.metachris.dev/about/>About</a></li><li class=navigation-item><a class=navigation-link href=https://www.metachris.dev/posts/>Posts</a></li><li class=navigation-item><a class=navigation-link href=https://www.metachris.dev/projects/>Projects</a></li><li class=navigation-item><a id=dark-mode-toggle class=colorscheme-toggle title="Toggle light/dark theme" style=cursor:pointer><span id=theme-icon>ðŸŒ™</span></a></li></ul></section></nav><div class=content><section class="container post"><article><header><div class=post-title><h1 class=title>Machine Learning on Amazon AWS GPU Instances</h1></div><div class=post-meta><div class=date><span class=posted-on><time datetime=2015-11-22T00:00:00Z>November 2015
</time></span><span class=reading-time>Â· 2 minutes read</span></div></div></header><div class=single-content><p>Machine learning algorithms regularly utilize GPUs to parallelize computations, and <a href=http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using_cluster_computing.html>Amazon AWS GPU Instances</a> provide cheap and on-demand access to capable virtual servers with NVIDIA GPUs.</p><p><a href=http://aws.amazon.com/ec2/instance-types/#gpu>GPU Instances</a> come in two flavors: <i>G2.2xlarge</i> and <i>G2.8xlarge</i>:</p><table><thead><tr><th>Model</th><th>GPUs</th><th>vCPU</th><th>Mem (GiB)</th><th>SSD Storage (GB)</th></tr></thead><tbody><tr><th>g2.2xlarge</th><td>1</td><td>8</td><td>15</td><td>1 x 60</td></tr><tr><th>g2.8xlarge</th><td>4</td><td>32</td><td>60</td><td>2 x 120</td></tr></tbody></table><p>The GPU instances feature <a href=http://www.bit-tech.net/hardware/cpus/2012/03/06/intel-xeon-e5-2670-review/1>Intel Xeon E5-2670</a> (Sandy Bridge) Processors and NVIDIA GPUs with 1,536 CUDA cores and 4GB of video memory each.</p><hr><h2>Tips & Tricks</h2><p>Several machine learning frameworks such as <a href=https://github.com/torch/torch7>Torch</a> and <a href=http://deeplearning.net/software/theano/>Theano</a> as well as Amazon itself provide AMIs (Amazon Machine Images) with pre-installed dependencies and NVIDIA kernel drivers:</p><ul><li><a href=https://github.com/torch/torch7/wiki/Cheatsheet#ec2-public-ami>Torch AMI</a></li><li><a href=https://github.com/andreasjansson/simple-aws-gpu-setup>Theano AMI Howto</a></li><li><a href="http://aws.amazon.com/marketplace/search/results/?searchTerms=NVIDIAGRID">Amazon AMIs</a></li></ul><p>Use <a href=https://aws.amazon.com/ec2/spot/>spot instances</a> - they&rsquo;re much cheaper for GPU instances!</p><ul><li>Pick a price that has been steady for a while</li><li>$0.10/hr often gets you a g2.xlarge instance, even for a few days continuously</li><li>You can view price graphs for the instance type in the <a href=http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-spot-instances-history.html>AWS console</a>.</li></ul><p>Spot instances get a 2 minute notice before being shut down. You can use <a href=http://aws.amazon.com/sdk-for-python/>boto</a> (AWS SDK for Python) to check the timestamp for when that will occur.</p><p>Make sure to snapshot your models, otherwise you might lose training time and have to start over. You can save the snapshots to S3 (depending on the size of the model).</p><p>Create an AMI with all dependencies pre-installed so you don&rsquo;t waste time installing those when the instance spins up.</p><p>For very large datasets use their <a href=https://aws.amazon.com/ebs/pricing/>Elastic Block Storage (EBS)</a>. It&rsquo;s basically an on-demand SSD you can attach to instances when they spin up.</p><hr><h2>References</h2><ul><li><p><a href=http://aws.amazon.com>Amazon AWS</a></p><ul><li><a href=http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using_cluster_computing.html>AWS GPU Instances Docs</a></li><li><a href=http://aws.amazon.com/ec2/instance-types/#gpu>AWS Instance Types</a></li></ul></li><li><p><a href=https://github.com/torch/torch7>Torch</a></p><ul><li><a href=https://github.com/torch/torch7/wiki/Cheatsheet#ec2-public-ami>Torch Public AMI</a></li><li><a href=https://github.com/torch/torch7/wiki/Cheatsheet>Torch Cheat Cheet</a></li><li><a href=https://github.com/brotchie/torch-ubuntu-gpu-ec2-install>Install Guide</a></li><li><a href=http://blog.titocosta.com/post/110345699197/public-ec2-ami-with-torch-and-caffe-deep-learning>Another Install Guide</a></li></ul></li><li><p><a href=http://deeplearning.net/software/theano>Theano</a></p><ul><li><a href=https://github.com/andreasjansson/simple-aws-gpu-setup>Setup Guide</a></li><li><a href=http://markus.com/install-theano-on-aws/>Another Setup Guide</a></li><li><a href=http://deeplearning.net/software/theano/install_ubuntu.html#install-ubuntu>Install on Ubuntu Docs</a></li></ul></li><li><p><a href=http://www.tensorflow.org/>TensorFlow</a></p><ul><li><a href=https://gist.github.com/Hello1024/bfbcb4616aadee62c68e>Guide for AWS</a></li></ul></li></ul><hr class=spaced><p>If you have suggestions, feedback or ideas, reach out to <a href=https://twitter.com/metachris target=_blank>@metachris</a>!</p></div><hr><div style=height:14px></div><div style=float:right><div class=tags><svg width="16" height="16" viewBox="0 0 20 20" fill="currentcolor" aria-hidden="true" style="display:inline-block;vertical-align:text-bottom"><path fill-rule="evenodd" d="M17.707 9.293a1 1 0 010 1.414l-7 7a1 1 0 01-1.414.0l-7-7A.997.997.0 012 10V5a3 3 0 013-3h5c.256.0.512.098.707.293l7 7zM5 6a1 1 0 100-2 1 1 0 000 2z" clip-rule="evenodd"/></svg><a href=https://www.metachris.dev/tags/machine-learning/>Machine Learning</a></div></div><div style=clear:both></div><div class=bottomAbout style=display:flex><div style=flex-grow:2><script async src=https://platform.twitter.com/widgets.js></script><a href=https://twitter.com/share class=twitter-share-button data-show-count=false>Tweet</a><br><a href=https://twitter.com/metachris class=twitter-follow-button data-show-count=false>Follow @metachris</a></div><div style=margin-top:0><a href=https://twitter.com/metachris><img src=https://www.metachris.dev/images/profile2-round.png alt=Chris class=profile style=max-width:60px></a></div></div><hr><div class=bottom-post-links><div class=prev><span class=title>OLDER POST</span><br><a href=https://www.metachris.dev/2015/11/david-beazley-python-concurrency-from-the-ground-up-live-pycon-2015/>David Beazley - Python Concurrency From the Ground Up (LIVE @PyCon 2015)</a></div><div class=next><span class=title>NEWER POST</span><br><a href=https://www.metachris.dev/2015/11/python-tools-for-string-unicode-encoding-decoding-printing/>Python Helpers for String/Unicode Encoding, Decoding and Printing</a></div></div><footer><a id=comments></a><script src=https://utteranc.es/client.js repo=metachris/metachris.dev-comments issue-term=og:title theme=preferred-color-scheme crossorigin=anonymous async></script></footer></article></section></div><footer class=footer><section class=container></section></footer></main><script src=https://www.metachris.dev/js/dark-mode.min.6948493aa1da5fe4e63b34961a67cde1361353b72c9e2d61f024a34872147559.js></script><script defer src=https://cloud.umami.is/script.js data-website-id=5434b4c9-8ffe-4321-ad55-33012bbb5e73></script><script async src="https://www.googletagmanager.com/gtag/js?id=UA-168016633-1"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","UA-168016633-1")</script></body></html>